# macros to include
load = ndlGoMacros

# the actual NDL that defines the network
run = DNN

ndlGoMacros = [
    BoardSize = 19
	BoardCellNb = 361
	KernelSize = 3

	#ManhattanMask = ImageParameter( 3, 3, 16,  init="fromFile",  initFromFilePath="ManhattanKernelSimple.txt", learningRateMultiplier=0, imageLayout=$imageLayout$)
	
	#ManhattanMask = LearnableParameter( 16, 9, init="fromFile",  initFromFilePath="ManhattanKernel.txt", learningRateMultiplier=0)
	
	#ManhattanMask = Parameter( 3, 3, init="fromFile",  initFromFilePath="ManhattanKernelSimple.txt")
    
		
    features = ImageInput(BoardSize, BoardSize, 1, imageLayout=$imageLayout$)
    labels = ImageInput(BoardSize, BoardSize, 1, imageLayout=$imageLayout$)
]

DNN=[

    # conv1
    
    cMap = 32
    hStride = 1
    vStride = 1
	
	 scValue = 1
    expAvg = 1
    
    convWScale = 10
    convBValue = 1
	
	
    # weight[cMap, kW * kH * inputChannels] 3 * 3 * 1 = 9
    
	conv1_act = ConvBNReLULayer(features, cMap, 9, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue, scValue, expAvg)
	#conv1_act = ConvReLULayer(features, cMap, 9, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue)
	#conv1_act = MaskedConvReLULayer(ManhattanMask, features, cMap, 9, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue)
   
    # conv2
      
    # weight[cMap2, kW * kH * cMap] 3 * 3 * 32 = 288
	
	conv2_act=ConvBNReLULayer(conv1_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue, scValue, expAvg)
	#conv2_act = ConvReLULayer(conv1_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue)
    #conv2_act = MaskedConvReLULayer(ManhattanMask, conv1_act, cMap, 144, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue)
	
	# conv3 ConvSigLayer 
	
	conv3_act = ConvBNReLULayer(conv2_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue, scValue, expAvg)
	#  ConvBNReLULayer(featScaled, cMap1, 25, kW1, kH1, hStride1, vStride1, convWScale, convBValue, scValue, expAvg)
    #conv3_act = ConvReLULayer(conv2_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue)
	
	
	# conv4
	
	conv4_act = ConvBNReLULayer(conv3_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue, scValue, expAvg)
    #conv4_act = ConvReLULayer(conv3_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue)
	
	# conv5
     conv5_act = ConvBNReLULayer(conv4_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue, scValue, expAvg)
	 # conv5_act = ConvSigLayer(conv4_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue)
	
	# conv6
     conv6_act = ConvBNReLULayer(conv5_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue, scValue, expAvg)
	# conv6_act = ConvSigLayer(conv5_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue)
	
	# conv7
     conv7_act = ConvBNReLULayer(conv6_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue, scValue, expAvg)
	# conv7_act = ConvSigLayer(conv6_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue)
	
	# conv8
     conv8_act = ConvBNReLULayer(conv7_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue, scValue, expAvg)
	# conv8_act = ConvSigLayer(conv7_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue)

	# conv9
	conv9_act = ConvBNReLULayer(conv8_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue, scValue, expAvg)
    # conv9_act = ConvSigLayer(conv8_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue)

	# conv10
	conv10_act = ConvBNReLULayer(conv9_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue, scValue, expAvg)
    # conv10_act = ConvSigLayer(conv9_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue)

	# conv11
	conv11_act = ConvBNReLULayer(conv10_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue, scValue, expAvg)
    # conv11_act = ConvSigLayer(conv10_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue)

	# conv12
	conv12_act = ConvBNReLULayer(conv11_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue, scValue, expAvg)
    # conv12_act = ConvSigLayer(conv11_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue)	 
	 
	 # conv13
    # conv13_act = ConvSigLayer(conv12_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue)	 
	 
	 # conv12
    # conv14_act = ConvSigLayer(conv13_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue)	 
	 
	 # conv12
    # conv15_act = ConvSigLayer(conv14_act, cMap, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue)	 
		
		
	# weight[cMap, kW2 * kH2 * cMap1] 3 * 3 * 32 = 288
	ol =  ConvSigLayer(conv12_act, 1, 288, KernelSize, KernelSize, hStride, vStride, convWScale, convBValue)
	#ol = Sigmoid(h1)
	
    
    
    #ce = CrossEntropyWithSoftmax(labels, ol)
	ce = SquareError(labels, ol)
	
	
	#err = ErrorPrediction(labels, ol)
	#err = SquareError(labels, ol)
	ol2 = SaturatedMidUnitThreshold(ol)
	err = SumElements (XorOp (labels, ol2))
	
	
    # Special Nodes
    FeatureNodes = (features)
    LabelNodes = (labels)
    CriterionNodes = (ce)
    EvalNodes = (err)
    OutputNodes = (ol)
]

